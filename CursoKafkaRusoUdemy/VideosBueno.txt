KRAFT
Zookeeper esta obsoleto, ahora se usa kraft. Principal ventaja:  Kafka brokers now manage metadata internally using a Raft-based consensus protocol (antes la metadata de los topics era gerenciada por zookeeper).
Se hacen una serie de movimientos en consola para configurar kraft antes de levantar un broker desde carpeta /bin con comando: kafka-server-start.sh (.bat  para windows) config/kraft/server.properties 
siendo server.properties un archivo q se modifica si queremos tener mas de un broker.

KAFKA CLI
Se corre  siempre kafka cli desde la carpeta /bin de donde se instalo kafka.
kafka-topics.sh -->para crear topics


KEYS
Los comandos de las primeras partes antes de producer microservice están en los .pdf del curso, son comandos de Kafka .cli.
Lo importante es q si se quiere seguir un orden de la secuencia de mensajes (es decir que si se comitea mensaje 1 primero y mensaje 2 después en el producer, se reciba mensaje uno y mensaje 2 despues en el consumer), debe ponerse un
key (del key value,ya q el mensaje es siempre el value y va a estar presente). Todos los mismos key van a  la misma partición y de esta manera se mantiene la secuencia, de lo contrario Kafka manda los mensajes a distintas particiones y
como las particiones son leidas por diferentes consumers,  nada asegura que se respete la secuencia).

Llamada  Asincrona
La idea es mandar un post request desde postman para crear un producto, guardarlo en la bbdd primero, luego mandarlo por kafka a un topic y mandar el response del post de vuelta a kafka con el productID.
En la sección Kafka Producer, send message Asyncronously, explica que en el servicio en este caso (o donde sea) siempre hay que guardar en bbdd primero antes de instanciar el evento (CreatedProductEvent) en el servicio y de luego mandarlo asíncronamente. 
Para mandarlo asíncronamente con Spring, es inyectando por dependencia (lo hizo por constructor) el bean KafkaTemplate y luego con método send. Solo con esto basta y sobra para enviar el mensaje por Kafka y podremos mandar el productID al cliente en postman ya mismo 
por rest http en el controler, pero sin confirmación de si se mandó o no el mensaje. Si queremos confirmación de que se mando o no el mensaje en Kafka (ojo, sigue siendo asíncrono, o sea no espera), debemos crear un completableFuture con Result (éxito) y Exception(fracaso).
El cliente va a tener su productID en postman generalmente antes de que tengamos la confirmacion de envio exitoso o error (o sea el  completablefuture).

Llamada Sincrono.
Si queremos confirmacion de que el mensaje fue enviado o que fallo antes de mandar el productID al cliente en postman, debemos hacerlo en forma sincrona agregando .get(). (Ver codigo de ProductsMicroservice en intellij q esta en este mismo directorio). 

Acknoledgement-InSyncReplicas--> Se recomienda ver los .pdf !!!
Supongamos que tenemos 5 brokers, cada una con una replica de una particion. Si esperamos un acknoledgment de cada uno de los 5 brokers nuestra performance disminuye. Por ello, lo ideal es esperar acknoledgment de
un numero prudente de replicas (2 o 3), esto se hace con la propiedad --replication.factor=5 --config.min.insync.replicas=2
Delivery timeout (tiempo total de envio de un mensaje) = Linger (tiempo que esperamos que se acumulen los mensajes en el batch antes de enviarlo al broker) + Request timeout (tiempo desde que enviamos efectivamente el batch).
Para modificar alguna propiedad (como min.insync.replicas por ejemplo) de un topic ya creado se usa kafka-configs.sh --alter en CLI.
La prueba q hizo fue la siguiente: Levantó 3 servidores de kraft e hizo correr el proyecto del producer (que en application.properties tiene spring.kafka.producer.acks=all ) . Levantó un consumer con cli. Recordar que en la linea anterior aca
habia modificado el topic  para insync replicas = 1. Tiró mensajes en postman al proyecto del producer y cuando detuvo dos de los 3 brokers, le dio un error en postman y el consumer ya no recibió nada.
Posteriormente seteó en application.properties retries=10 (numero de reintentos) y retry.backoff.ms=1000 (tiempo entre reintentos). Cuando probo con un solo broker mostro que probo 10 veces con intervalo de 1 segundo (lo mustra los logs del proyecto)
Luego hizo la misma prueba agregando delivery.timeout  de 12000 ms en el application.properties. Mostro error durante 2 minutos en los logs (cuando hace varios retries) y luego se detuvo.

Idempotent Producer.
Si mandamos un mensaje a un broker y el broker efectivamente lo recibe, pero se cae antes de mandar el acknoledgment entonces no sabremos que el mensaje se envió efectivamente y se enviará en un retry, lo que producirá q el mensaje este duplicado en el log.
Para prevenir esto, el producer de kafka por defecto es idempotene, es decir reconoce si un mensaje ya esta en el log antes de insertarlo. Si esta en el log,  pero falta el acknoledgment solo manda el acknoledgment, pero no inserta nada.
Segun el ruso esta configuarcion, q por defecto ya viene incluida, es facil desconfigurarla, por lo q es mejor setearla explicitamente en el application.properties (ver video pq me dio lata escribir la configuracion) o con @Bean en el producer.

--TODO CONFIGURATIONS.PROPERTIES FILE

Consumers
Una particion va a un consumer y un topic va a un consumer group.
Creó un proyecto para el consumer (EmailNotificationMicroservice) que yo lo tengo en carpeta Section-9-Kafka-Consumer-final-EmailNotificationMicroservice.
En el application.properties seteó un puerto igual a cero, pa q el proyecto del consumer ocupe un puerto al azar. Ademas, setió spring.kafka.consumer.bootstrap.servers=localhost:9092. Bootstrap server is used for initial connection to Kafka cluster.
As a bootstrap server I will specify localhost and then the port number 9092, the localhost and then the port number 9092. That is the address of one of my brokers in Kafka cluster. Once this microservice or this Kafka consumer connects to one broker, it will be able to connect and work with all other brokers as well.
Setió tambien spring.kafka.consumer.group.id:product-created-event. En este caso todos nuestros microservicios formaran un solo consumer group.
Creó la clase ProductCreatedEventHandler que acuará como Listener (la marcó con @KafkaListener), y que contendrá uno o varios @KafkaHandler, cada uno independiente para un respectivo evento
Creó el proyecto core (que tiene clases  comunes para los  proyectos del producer y el consumer) agregando ProductCreatedEvent. Con mvn install queda listo para ocuparlo tanto por EmailNotificationMicroservice como por ProductsMicroservice.
Corre los brokers por comando, corre ProductsMicroservice y EmailNotificationMicroservice. Le pega a ProductsMicroservice por postman mandando un post con un producto y comprueba en los logs de EmailNotificationMicroservice q el producto ha sido recibido por el consumer.
En este punto ya sabe q el consumer funciona, pero quiso crear igual una clase de configuracion de beans (KafkaConsumerConfiguration) con lo que tiene en el application.properties. La prueba fue igual a la anterior.

Kafka consumers: Errores de deserializacion.
Se explica esta seccion con lineas de codigo en la clase KafkaConsumerConfiguration.

En seccion Dead Letter Topic se crea un topic llamado Dead Letter Topic desde EmailNotificationMicroservice como producer, con todos los mensajes que han fallado (incluyendo por cierto los de la seccion Kafka consumers: Errores de deserializacion.
para ello en la clase KafkaConsumerConfiguration creó dos beans para hacer funcionar el producer de deadlettertopic.
Para probar levantó EmailNotificationMicroservice y ProductsMicroservice. Primero creó un producto exitoso, al igual q antes el  consumer lo leyó bien.
Se fue a la terminal y mando un producto errado con String en vez de Json, y no le dio error en el consumer (al igual q antes tambien).
Se fue a la terminal de nuevo y levantó el topic product-created-events-topic.DLT (nomenclatura q se usa por convencion) que sera nuestro dead letter topic y que se creó por codigo en KafkaConsumerConfiguration. Al levantar vio que tenia el mensaje defectuoso con formato string enviado anteriormente.

Exceptions and Retries.  Hasta ahora el mensaje q mandamos a DLT sabiamos q era NO reenviable (retriable) pq era un asunto de formato (string json). Pero q pasa si hay otro tipo de error como q se caiga un microservicio p.ej.
Lo q hay q hacer entonces es primero preguntarse si el error es retriable o no. Si es retriable hay q configurar wait time y number of times to retry. Si no es retriable lo mandamos a DLT
Creó dos clases, NotRetryableException y RetryableException, las agregó en el metodo kafkaListenerContainerFactory de la clase de configuracion. A continuacion levantó todo y probó en postman con un post para crear un producto repetido, lo q provocó un NotRetryableException en los logs.
Luego, en metodo @KafkaHandler handle() escribió mas personalizaciones para arrojar errores mas especificos para RetryableException y NotRetryableException. Uno es quien determina si un error es  retryable o no. La idea en nuestro caso es q despues de 3 intentos cada 5 segundos, el  error se considere NotRetryableException (ver linea de FixedBackOff())
Abrió Mockservice (pasó el src en el curso) y lo probó en postman. Mockservice simulará distintas respuestas al ser llamado desde EmailNotificationMicroservice mediante RestTemplate.
A continuacion levantó ProductsMicroservice, EmailNotificationMicroservice, Mockservice y por kafka-cli creó el consumer de DLT por comando. En EmailNotificationMicroservice creó varios breakpoints en metodo @KafkaHandler handle(). En postman mandó un nuevo producto y fue probando caso a caso para RetryableException y NotRetryableException.

ConsumerGroups.
Generalmente (aunque no siempre) se estila que los consumers de un consumer group determinado sean instancias del mismo microservicio. En este curso se estila que consumer=instancia de microservicio de ahora en adelante
Rebalancing es el proceso en que los consumers se crean o eliminan automaticamente de acuerdo a la demanda. Cada consumer dentro del consumergroup manda un heartbeat al broker para que se sepa cuantos consumers se tienen disponibles en cada  momento.
Si se crean mas instancias que particiones, dará un sit idle (consumidor ocioso).
El consumergroup lo setea en el  application.properties y lo llama en consumerFactory() de la clase de configuracion.  Se puede hacer mediante  Bean o directamente en @KafkaListener tambien.
A continuacion corrio tres instancias distintas de EmailNotificationMicroservice desde la  carpeta del curso con comando: mvn spring-boot:run (con server.port=0 en application.properties los levanta en puertos aleatorios). En el
mismo log que resulta al correr estas instancias se puede ver la particion a la que ha sido asignada (tiene 3 particiones para 3 consumers). Luego bajó dos instancias y vió que las instancia restante consume las tres particiones.
Para la prueba volvio a levantar las tres instancias, creó un nuevo producto en postman y vio q solo una instancia recibió el mensaje, no las otras dos.

IdempotentConsumer
Si en un primer mensaje un consumer recibe un mensaje desde un topic (receives message) y produce actualizacion de una base de datos(process message), pero falla al realizar el acknoledgement al broker, el topic no sabe que
este mensaje ya ha sido consumido y procesado y el mensaje sigue disponible en la particion, lo q es un problema. Para solucionarlo existen varias alternativas como transactions, idempotent producer y idempotent consumer.
Con idempotent consumer un consumer pueda recibir un mismo mensaje dos veces sin problema, pero nos aseguramos q solo lo procesará una vez. Primero antes de actualizar la bbdd veremos si la bbdd ya esta actualizada antes (producto del mismo mensaje anterir) y si es asi solo se le enviará la señal
al broker para q el mensaje no siga disponible. Para ello:
-Creó un unique identifier para el mensaje (aparte del key) en metodo createProduct() en proyecto ProductsMicroservice.
-Agregó en EmailNotificationMicroservice en @KafkaHandler handle() lineas para recibir el unique identifier
-Agregó las dependencias de h2 y spring-boot-starter-data-jpa en el pom.
-Configuró h2 en applications.properties
-Creo la JPA Entity class ProcessedEventEntity en EmailNotificationMicroservice
-Creo la interfaz ProcessedEventRepository como JPARepository en EmailNotificationMicroservice
-Creó la logica de negocio para guardar en la bbdd en @KafkaHandler handle() en EmailNotificationMicroservice.  Este metodo lo volvió transaccional.
-Creó la logica de negocio para ver si el mensaje ya estaba guardado en la bbdd desde antes por medio del unique identifier. Esto lo hizo en el  metodo @KafkaHandler handle().
-Finalmente probó. Para ello puso un breakpoint en @KafkaHandler handle() antes de la linea para ver si el mensaje ya estaba guardado en la bbdd y levantó EmailNotificationMicroservice en debugmode. Luego levantó ProductsMicroservice (previo hardcodeo en el IDE de messageID (le puso 123 en vez de UUID.RandomUUID())) y Mockservice normalmente.
Mandó un producto con un post en postman y continuó desde el breakpoint hasta el final, observando q el programa pasa por la logica de negocio de guardar en la bbdd 
Levantó la bbdd de h2 en un browser y vió q el producto estaba guardado sin problemas.
Luego mandó a crear el mismo rpoducto con en mismo messageID =123,  continuó desde el breakpoint hasta el final, observando q el programa ahora no pasa por la logica de negocio de guardar en la bbdd ni esta duplicado en la bbdd en el browser.

Transactiones

Transactions-->Los conceptos explicado por Bharath en su curso de entrevista Java son válidos para cualquier tipo de transacción, pero Bharath lo enfocó desde punto de vista entre microservicio y base de datos,  no de kafka.
Kafka Transactions -->entre microservicios de nuestra empresa
JPA Transactions -->entre microservicio y base de datos (es lo mismo q DataBase Transaction)
Compensating transaction-->entre un microservicio nuestro y otro de otra empresa (escapa al ambito de este curso).
Distributed transactions-->entre diferentes bases de datos (al sacar de una bbdd y poner la plata en otra), esta es la q explica Bharath en el curso de entrevista java (la q ademas del transactionManager tiene varios resourceManagers, uno por bbdd).
En esta sección del  curso tendremos:
-TransferService: microservicio que actua como provider para los otros dos.
-WithdrawalService: microservicio que consume de TransferService y retira dinero desde las cuentas de usuarios.
-DepositService: microservicio que consume de TransferService y deposita dinero en las cuentas de usuarios.
Estos 3 proyectos funcionan bajo el paradigma de commited transaction (q es lo mismo q TRANSACTIONS_READ_COMMITED, o sea esta previniendo Dirty Reads)

En los videos siguientes configuró transacciones en TransferService. Para ello:
-Anotó la configuracion de idempotent producer en el application.properties.
-La rescató con @Value en la clase de configuracion y lo unió en los props con TransactionalIDConfig. Con ello (sigo en inglés acá) if my application crashes in the middle of transaction, Kafka can then use this transaction
ID to identify which messages were part of incomplete transaction and make sure that these messages are not processed until transaction is complete.
-Setió el proyecto como producer con los beans necesarios para ello (ProducerFactory, KafkaTemplate y TransactionManager).
-Anotó  el método transfer() que es el metodo q efectua la logica de negocio para retiro y deposito de dinero entre microservicios como @Transactional. Esto significa que agarra el TransactionManager q seteamos como bean en la clase de configuracion.
-Explicó q @Transactional sin parametros hace rollback solo para RuntimeExceptions.  Si se quiere hacer rollback para CheckedExceptions hay q definirlo explicitamente en los argumentos.
-Setió el isolation level en los  consumidores (no en el producer!), q pa kafka entre microservicios por defecto es TRANSACTIONS_READ_UNCOMMITED.  Para ello, en el application.properties de los proyectos WithdrawalService y DepositService setió el isolation level de read commited (previene uncommited reads). Los rescató con @value y y los pasó en las respectivas clases de configuración de estos proyectos,
-Probó todo el sistema levantando WithdrawalService y DepositService y Mockservice. TransferService lo levantó en modo debug y puso un breakpoint en callRemoteServce(). Al debuguear vió que le corria el codigo para retirar dinero.
Luego bajó el Mockservice y reaunudó el debugging. Ya que MockService fue incapaz de reponder el http request enviado por DepositService, vimos que el WithdrawalService echó para atrás lo q habia hecho y el mensaje enviado desde TransferService nose consumió en ninguno de los dos topics.
Nota: al probar hay que ir revisando el envio y recepcion de mensajes buscando en los logs "KafkaTransactionManager". Si hay rollback no aparecerá el "KafkaTransactionManager" en los logs.

DataBase Transactions and Kafka Transactions.
Ahora necesita que q TransferService ademas de actuar como producer para WithdrawalService y DepositService (Kafka Transactions orquestada por KafkaTransactionManager) pueda guardar en una bbdd (JPA Transactions orquestada por JPATransactionManager).
Para ello en TransferService:
-Agregó las dependencias de h2 y starter-data-jpa en TransferService.
-Agregó las clases TransferEntity y TransferRepository en TransferService.
-Creó el bean jpaTransactionManager llamado "transactionManager" q es el JPATransactionManager encargado de manejar las transacciones en la bbdd.
-Usó el método transfer() para guardar en bbdd.
-Sincronizó escribiendo @Transactional("transactionManager"), que es el bean de Spring JPA. El concepto acá es utilizar el bean de Spring JPA para que tome todo el bloque como una single unit
para la transacción, pero internamente cuando el código llegue a la parte q ocupa kafkaTemplate sabe q tiene que usar kafkaTransactionManager para gestionar la parte de la transaccion con los otros dos microservicios.
-Cambió la configuracion de los logger en application.properties pa q le saliera los logging de la transaccion a la bbdd.
-Probó de la misma forma q en la seccion inmediatamente anterior (linea 119 de este documento a menos que haya cambiado algo), con el mismo breakpoint en TransferService, solo que esta vez ademas de los logs prestó atencion a la consola de
h2 para ver si se le guardaba el producto q le estaba mandando por postman (caso commited o exitoso) o si no se lo guardaba (caso rollback o fallido).

Nota: en las dos secciones de tests de integracion no escribí mucho,pero lo importante es saber:
1. En kafka se privilegian test de integracion por separado: uno para producer y otro para consumer, en vez de pruebas unitarias.
2. En ambos casos con @EmbededKafka podemos tener un servidor de kafka embebido al correr los tests, lo qnos permite hacer las pruebas sin necesidad de levantar absolutamente nada. 
3. Si bien contaremos con servidor de kafka embebido, igual necesitamos configurar parametros como nombres de topics, particiones, etc. para la simulación. Esto se logra con los parametros de application.properties
IntegrationTests - KafkaProducer
El código esta complejo de ver (esta en el proyecto mio q dice TestIntegrationProducer). Pa los test de integracion necesita simular primero lo q manda por postman y segundo todo elambiente con los brokers y topic para poder recibir un mensaje simulado y comparar
si es lo mismo q simuló mandar por kafka. Esto corre en el IDE,en ninguna otra parte. 

IntegrationTests - KafkaConsumer
Va a ocupar EmailNotificationMicroservice, particularmente desea comprobar q el metodo handle() recibe correctamente los mensajes que le estan llegando de kafka, pero no la parte de guardar en bbdd por jpa ni la llamada a mockservice q tambien
estan en este metodo, por ello estas dos cosas serán mockeadas, por lo q el test de integracion solo sera para los mensajes kafka.
El proyecto donde esta esta seccion esta en EmailNotificationMicroservice-IntegrationTests.
-Hardcodeó  lo que mandaria por postman.
-Creó el mock pal jpa y pal rest
-Creó un spy para el  evento (ProductCreatedEvent), ya q igual necesita el evento real, por ello solo hace stub al metodo handle().
-Corrió el test sin levantar nada.




