*QUE ES DOCKER
Docker es un administrador de contenedores. 
Un contenedor es una caja de herramienta asilada con un porción de un sistema operativo para ejecutar aplicaciones en nuestra maquina host.
Es un empaquetado del código y dependencias para ejecutar que ese código, la aplicación (ejemplo aplicación con Spring + JDK runtime).
Un mismo contenedor que se ejecuta siempre debe reproducir exactamente el mismo comportamiento de la aplicación, sin importar dónde o quién lo ejecuta

*IMAGENES VS CONTENEDORES
La imagen es una plantilla que contiene el código y ambiente necesario(runtime, herramientas, librerias). Los contenedores son instancias de esta plantilla que ejecutan la aplicacion y el
ambiente necesario para su ejecución

*DOCKERFILE
Podemos descargarnos imagenes desde hub.docker.com que ya estan listas para java, mysql, etc. La versión de la imagen se busca en tag o en el buscador.
Además podemos configurar nuestras propias imagenes, con un archivo de configuración llamado Dockerfile. Este archivo debemos generarlo al mismo nivel del pom en los directorios.

Para generar imagenes debemos tener nuestro jar generado, pero antes de generarlo notar que hay que hacer un cambio en el application properties, para que
se apunte a la bbdd local desde el container (spring.datasource.url=jdbc:mysql://host.docker.internal:3306/msvc_usuarios) 

Se genera la imagen (docker build -t nombreImagenACrear.) y luego se ejecuta el container mediante la id de la imagen generada (docker run -p 8000:8001 idImagen). Se puede incluso probar en postman (recordar q se prueba siempre en postman con puerto externo, o sea 8000 en este caso). No se necesita estar conectado a la bbdd para la imagen, pero sí para el contenedor.

Si se desea acceder desde otro servicio (msvc_usuarios), en el cliente rest del otro servicio se debe cambiar la url a tambien a @FeignClient(name="msvc-cursos", url="host.docker.internal:8002")

Cada linea del dockerfile corresponde a una capa de la imagen. Las capas permanecen en el caché de docker hasta que se cambia algo en ellas, por lo que si creamos un container a partir de esta imagen
al ejecutarse el container, si no hemos modificado el dockerfile se rescata cada capa desde el caché de la ejecución anterior y no del dockerfile. Si modificamos algo que corresponde a las capas de la imagen en el dockerfile(el código por ejemplo), ahi si que se obtiene la capa desde el dockerfile y no del caché.

Podemos optimizar el Dockerfile para que se genere el jar con la imagen en vez de estarlo haciendo nosotros por comandos (ver dockerfile modificado). 
Para generar el jar con la imagen ejecutó el siguiente comando desde el proyecto principal curso-kubernetes : docker build -t nombreImagenACrear . -f.\msvc-usuarios\Dockerfile (el punto hace alusion a donde estamos parados, en este caso curso-kubernetes).
En el caso que nosotros generamos jar por comandos se demora menos en crear la imagen, ya que al generar el jar obtiene las librerias de nuestro repositorio local. Al hacerlo por imagen descarga las librerias desde internetla primera vez (en las ejecuciones siguientes sin embargo quedan en la caché)!
Sin embargo si queremos modificar algo en el código tiene la ventaja que no tenemos que estar generando nosotros el jar cada vez.

El dockerfile puede trabajarse tambien por medio de etapas (cada FROM etapa es un stage o etapa). L segunda etapa se basa en la primera y asi sucesivamente. Si no se modifica nada de la primera etapa y solo se mofifica algo en la segunda, la ejecucion para la primera etapa es rapisisima, aunque en realidad si no se tuviera por etapas tambien sería rápida la ejecución para la primera, porque quedaría en caché.
Sin embargo la principal ventaja es que se pueden separar diferentes etapas de ejecución para ver fallos en cada etapa.

*MODO INTERACTIVO
El modo interactivo permite trabajar dentro de docker como si fuera un terminal normal de linux. El entrypoint no permite hacer esto, debemos cambiarlo en el dockerfile por: CMD ["java","-jar","msvc-usuarios-0.0.1-SNAPSHOT.jar"]
Luego ejecutamos docker run -p 8001:8001 --rm -it idImagen /bin/sh. Entonces se abre /app (/app fue el nombre que dimos en el workdir del dockerfile) y entonces podemos trabajar con el terminal linux en docker. Despues salimos de /app con el comando exit
Podemos copiar un archivo desde nuestro directorio del proyecto a un contenedor en ejecucion en modo interactivo (en otro terminal) con: docker cp .\NombreArchivo.java idContainer:/a
pp/Login.java. 

*Docker-Compose
Debemos instalarlo, no basta con tener docker.
docker-compose up: Builds, (re)creates, and starts containers. It also attaches to containers for a service.
docker-compose run: Run one-off or ad-hoc tasks based on the business requirements. Here, the service name has to be provided and the docker starts only that specific service and also the other services to which the target service is dependent (if any). It is helpful for testing the containers and also for performing tasks
docker-compose start: Start the stopped containers, can't create new ones.

*COMUNICACION ENTRE COMPONENTES
En el application.properties debemos escribir: spring.datasource.url=jdbc:postgresql://localhost:host.docker.internal/nombreMicroservicio ; Ademas en el cliente rest debemos escribir el nombre del otro microservicio (con el que nos queremos comunicar, por ejemplo @FeignClient(name="msvc-cursos", url="msvc-cursos:8002") 
                                                                
Con cliente HTTP (Librerías Feign o RestTemplate) podemos conectarnos entre microservicios y bases de datos:
1. En local sin docker: seteando nombre de aplicacion y url propio en el application.properties y del microservicio que queremos comunicarnos en la clase del cliente http; para bbdd basta con setearlo en el application.properties, como siempre. (Se usa sencillamente localhost)
2. En local con docker: hay que crear un network en local y luego dockerizar cada microservicio y hacerlos correr en una red de docker previamente creada. Editar tanto  application.properties como clase cliente Http en cada microservicio poniendo el nombre del otro microservicio que deseamos llamar. Ojo que el name del otro microservicio va solo una vez o en la clase cliente http o en el application properties y lo mandamos llamar en la clase cliente rest.
Las bases de datos se pueden dejar fuera de la red docker o dockerizarlas y hacerlas parte de la red tambien, en cuyo caso habría que cambiar el application.properties en la linea del spring.datasource.url. dejándolo con el nombre del contenedor de la base de datos, por ejemplo: #spring.datasource.url=jdbc:postgresql://postgres14/msvc_cursos (en vez de #spring.datasource.url=jdbc:postgresql://host.docker.internal:5432/msvc_cursos que sería con la bbdd fuera de la red). En contenedores el local podemos ademas comunicar con internet, aplicaciones de la WWW mediante url de la api.
Además podemos setear las variables del application.properties de cada microservicio (como nombre de aplicacion y bases de datos, por ejemplo) como variables de entorno en el docker-compose y levantar todos los microservicios con el docker-compose.												
3. Entre instancias creadas manualmente en AWS (sin ECS): En el docker-compose de cada microservicio debemos especificar en nombre del container y la imagen del microservicio y en las variables de entorno (en el mismo docker-compose) especificamos la url del microservicio al q nos queremos conectar.
Cada docker compose (o sea cada container y por ende cada microservicio) lo ejecutamos en una instancia (maquina) diferente. Se puede usar un network en el docker compose, pero sino se crea uno por defecto. Naturalmente igual necesitamos un cliente HTTP en el proyecto.
4. Entre tareas creadas automaticamente en AWS (con ECS): Se comunican mediante DNS o IP publica fija obtenidas al setear un Load Balancer en los servicios que ejecutan las tareas. Estos DNS van en las variables de entorno que seteamos en la interfaz gráfica de EC2 cuando creamos (o editamos) los containers. Naturalmente igual necesitamos un cliente HTTP en el proyecto.
5. En local con dockerfile y minikube. Para conectarnos desde fuera del servicio (desde fuera del cluster): Por medio de la IP dada por un servicio con load balancer en minikube, con comando: minikube service msvc-cursos --url. Esto se pega en postman y se prueba con ruta GET Pminikube/puertoExterno. Naturalmente que para la comunicacion interna entre los microservicios igual necesitamos el cliente HTTP en el proyecto, además de nombre de microservicio en application.properties y url y nombre del microservicio al q queremos conectarnos escritos en el módulo de cliente http.
6. En local con dockerfile y spring cloud kubernetes.  Para conectarnos desde fuera del servicio (desde fuera del cluster): Por medio de la IP dada por Spring Cloud Kubernetes. Naturalmente que para la comunicacion interna entre los microservicios igual necesitamos el cliente HTTP en el proyecto, además de nombre de microservicio en application.properties y nombre del microservicio al q queremos conectarnos escritos en el módulo de cliente http, solo que ahora en este módulo prescindimos de la url del microservicio al q queremos conectarnos.



